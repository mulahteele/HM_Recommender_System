{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-13T23:26:42.697376Z","iopub.status.busy":"2022-08-13T23:26:42.697068Z","iopub.status.idle":"2022-08-13T23:27:35.01124Z","shell.execute_reply":"2022-08-13T23:27:35.008459Z","shell.execute_reply.started":"2022-08-13T23:26:42.697342Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","\n","df = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype={\"article_id\": str})\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:27:35.014974Z","iopub.status.busy":"2022-08-13T23:27:35.014545Z","iopub.status.idle":"2022-08-13T23:27:39.877793Z","shell.execute_reply":"2022-08-13T23:27:39.876998Z","shell.execute_reply.started":"2022-08-13T23:27:35.014934Z"},"trusted":true},"outputs":[],"source":["df[\"t_dat\"] = pd.to_datetime(df[\"t_dat\"])\n","df[\"t_dat\"].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:27:39.879259Z","iopub.status.busy":"2022-08-13T23:27:39.879005Z","iopub.status.idle":"2022-08-13T23:27:44.894538Z","shell.execute_reply":"2022-08-13T23:27:44.893844Z","shell.execute_reply.started":"2022-08-13T23:27:39.879206Z"},"trusted":true},"outputs":[],"source":["active_articles = df.groupby(\"article_id\")[\"t_dat\"].max().reset_index()\n","active_articles = active_articles[active_articles[\"t_dat\"] >= \"2019-09-01\"].reset_index()\n","active_articles.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:27:44.89668Z","iopub.status.busy":"2022-08-13T23:27:44.89635Z","iopub.status.idle":"2022-08-13T23:27:52.299727Z","shell.execute_reply":"2022-08-13T23:27:52.29904Z","shell.execute_reply.started":"2022-08-13T23:27:44.896643Z"},"trusted":true},"outputs":[],"source":["df = df[df[\"article_id\"].isin(active_articles[\"article_id\"])].reset_index(drop=True)\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:27:52.301432Z","iopub.status.busy":"2022-08-13T23:27:52.301162Z","iopub.status.idle":"2022-08-13T23:27:53.785893Z","shell.execute_reply":"2022-08-13T23:27:53.785127Z","shell.execute_reply.started":"2022-08-13T23:27:52.301397Z"},"trusted":true},"outputs":[],"source":["df[\"week\"] = (df[\"t_dat\"].max() - df[\"t_dat\"]).dt.days // 7\n","df[\"week\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:27:53.78753Z","iopub.status.busy":"2022-08-13T23:27:53.787262Z","iopub.status.idle":"2022-08-13T23:28:41.2124Z","shell.execute_reply":"2022-08-13T23:28:41.211594Z","shell.execute_reply.started":"2022-08-13T23:27:53.787496Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","\n","article_ids = np.concatenate([[\"placeholder\"], np.unique(df[\"article_id\"].values)])\n","\n","le_article = LabelEncoder()\n","le_article.fit(article_ids)\n","df[\"article_id\"] = le_article.transform(df[\"article_id\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:28:41.214104Z","iopub.status.busy":"2022-08-13T23:28:41.213843Z","iopub.status.idle":"2022-08-13T23:29:14.678936Z","shell.execute_reply":"2022-08-13T23:29:14.67822Z","shell.execute_reply.started":"2022-08-13T23:28:41.21407Z"},"trusted":true},"outputs":[],"source":["WEEK_HIST_MAX = 5\n","\n","def create_dataset(df, week):\n","    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n","    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n","    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n","    \n","    target_df = df[df[\"week\"] == week]\n","    target_df = target_df.groupby(\"customer_id\").agg({\"article_id\": list}).reset_index()\n","    target_df.rename(columns={\"article_id\": \"target\"}, inplace=True)\n","    target_df[\"week\"] = week\n","    \n","    return target_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n","\n","val_weeks = [0]\n","train_weeks = [1, 2, 3, 4]\n","\n","\n","val_df = pd.concat([create_dataset(df, w) for w in val_weeks]).reset_index(drop=True)\n","train_df = pd.concat([create_dataset(df, w) for w in train_weeks]).reset_index(drop=True)\n","train_df.shape, val_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:02.847839Z","iopub.status.busy":"2022-08-13T23:32:02.847226Z","iopub.status.idle":"2022-08-13T23:32:02.887134Z","shell.execute_reply":"2022-08-13T23:32:02.886338Z","shell.execute_reply.started":"2022-08-13T23:32:02.847803Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","import torch\n","from tqdm import tqdm\n","\n","class HMDataset(Dataset):\n","    def __init__(self, df, seq_len, is_test=False):\n","        self.df = df.reset_index(drop=True)\n","        self.seq_len = seq_len\n","        self.is_test = is_test\n","    \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        \n","        if self.is_test:\n","            target = torch.zeros(2).float()\n","        else:\n","            if not row.target:\n","                target = torch.tensor([0]).int()\n","            else:\n","                rand_target = np.random.choice(row.target,1)\n","                target = torch.tensor(rand_target).squeeze().int()\n","#             for t in row.target:\n","#                 target[t] = 1.0\n","#                 break\n","            \n","        article_hist = torch.zeros(self.seq_len).long()\n","        week_hist = torch.ones(self.seq_len).float()\n","        \n","        \n","        if isinstance(row.article_id, list):\n","            if len(row.article_id) >= self.seq_len:\n","                article_hist = torch.LongTensor(row.article_id[-self.seq_len:])\n","                week_hist = (torch.LongTensor(row.week_history[-self.seq_len:]) - row.week)/WEEK_HIST_MAX/2\n","            else:\n","                article_hist[-len(row.article_id):] = torch.LongTensor(row.article_id)\n","                week_hist[-len(row.article_id):] = (torch.LongTensor(row.week_history) - row.week)/WEEK_HIST_MAX/2\n","                \n","        return article_hist, week_hist, target\n","    \n","HMDataset(val_df, 64)[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:07.850873Z","iopub.status.busy":"2022-08-13T23:32:07.850547Z","iopub.status.idle":"2022-08-13T23:32:07.861013Z","shell.execute_reply":"2022-08-13T23:32:07.860165Z","shell.execute_reply.started":"2022-08-13T23:32:07.850837Z"},"trusted":true},"outputs":[],"source":["def adjust_lr(optimizer, epoch):\n","    if epoch < 1:\n","        lr = 5e-5\n","    elif epoch < 6:\n","        lr = 1e-3\n","    elif epoch < 9:\n","        lr = 1e-4\n","    else:\n","        lr = 1e-5\n","\n","    for p in optimizer.param_groups:\n","        p['lr'] = lr\n","    return lr\n","    \n","def get_optimizer(net):\n","    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n","                                 eps=1e-08)\n","    return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:14.844389Z","iopub.status.busy":"2022-08-13T23:32:14.843782Z","iopub.status.idle":"2022-08-13T23:32:14.848635Z","shell.execute_reply":"2022-08-13T23:32:14.847549Z","shell.execute_reply.started":"2022-08-13T23:32:14.844352Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:16.552106Z","iopub.status.busy":"2022-08-13T23:32:16.551845Z","iopub.status.idle":"2022-08-13T23:32:16.563584Z","shell.execute_reply":"2022-08-13T23:32:16.562463Z","shell.execute_reply.started":"2022-08-13T23:32:16.552076Z"},"trusted":true},"outputs":[],"source":["class HierarchicalSoftmax(nn.Module):\n","    def __init__(self, ntokens, nhid, ntokens_per_class = None):\n","        super(HierarchicalSoftmax, self).__init__()\n","\n","        # Parameters\n","        self.ntokens = ntokens#the number of ouput.(72582)\n","        self.nhid = nhid#dimension: the same length of customer dimension.(512)\n","\n","#         if ntokens_per_class is None:\n","#             ntokens_per_class = int(np.ceil(np.sqrt(ntokens)))\n","\n","        self.ntokens_per_class = ntokens_per_class#how many children one intermidiate node.(20)\n","\n","        self.nclasses = int(np.ceil(self.ntokens * 1. / self.ntokens_per_class))#intermidiate nodes.(3630)\n","        self.ntokens_actual = self.nclasses * self.ntokens_per_class#72600\n","\n","        self.layer_top_W = nn.Parameter(torch.FloatTensor(self.nhid, self.nclasses), requires_grad=True)\n","        self.layer_top_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n","\n","        self.layer_bottom_W = nn.Parameter(torch.FloatTensor(self.nclasses, self.nhid), requires_grad=True)\n","        self.layer_bottom_b = nn.Parameter(torch.FloatTensor(self.nclasses), requires_grad=True)\n","\n","        #self.softmax = nn.Softmax(dim=1)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","\n","        initrange = 0.1\n","        self.layer_top_W.data.uniform_(-initrange, initrange)\n","        self.layer_top_b.data.fill_(0)\n","        self.layer_bottom_W.data.uniform_(-initrange, initrange)\n","        self.layer_bottom_b.data.fill_(0)\n","\n","\n","    def forward(self, inputs):\n","        labels = torch.arange(self.ntokens_actual)###72600 \n","        batch_size, d = inputs.size()\n","\n","        label_position_top = (labels / self.ntokens_per_class).long()#which position is the top layer.###[0,0,..,0,....,3659,3659]\n","        label_position_bottom = (labels % self.ntokens_per_class).long()#which position is the bottom layer.###[0,1,2,..,19,1,2,...,19,..]\n","        \n","        layer_top_logits = torch.matmul(inputs, self.layer_top_W) + self.layer_top_b###[256, 3630]\n","        #layer_top_probs = self.softmax(layer_top_logits)#diretly output the logits\n","        \n","        \n","        multi_bias = self.layer_bottom_b[label_position_top].repeat(batch_size,1)###[256,72600]\n","        \n","        #self.layer_bottom_W[label_position_top]###[72600,512]\n","        #inputs##[256,512]\n","        layer_bottom_logits = torch.matmul(inputs,self.layer_bottom_W[label_position_top].T) + multi_bias###[256,72600]\n","        \n","        #layer_bottom_probs = self.softmax(layer_bottom_logits)\n","        \n","        layer_top_logits = layer_top_logits.repeat_interleave(self.ntokens_per_class,dim=1)###[256,72600]#match the top classes and the bottom classes.\n","        \n","        \n","        target_logits = torch.mul(layer_top_logits,layer_bottom_logits)#get the final logits\n","        #target_logits = layer_top_logits[torch.arange(batch_size).long(), label_position_top] * layer_top_logits[torch.arange(batch_size).long(), label_position_bottom]\n","\n","        return target_logits\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:21.710126Z","iopub.status.busy":"2022-08-13T23:32:21.70986Z","iopub.status.idle":"2022-08-13T23:32:22.136896Z","shell.execute_reply":"2022-08-13T23:32:22.136094Z","shell.execute_reply.started":"2022-08-13T23:32:21.710096Z"},"trusted":true},"outputs":[],"source":["class HMModel(nn.Module):\n","    def __init__(self, article_shape):\n","        super(HMModel, self).__init__()\n","        \n","        self.article_emb = nn.Embedding(article_shape[0], embedding_dim=article_shape[1])\n","        \n","#         self.article_likelihood = nn.Parameter(torch.zeros(article_shape[0]), requires_grad=True)\n","#         self.top = nn.Sequential(nn.Conv1d(3, 32, kernel_size=1), nn.LeakyReLU(),\n","#                                  nn.Conv1d(32, 8, kernel_size=1), nn.LeakyReLU(),\n","#                                  nn.Conv1d(8, 1, kernel_size=1))\n","        self.hier = HierarchicalSoftmax(72582, 512,ntokens_per_class = 20)\n","    def forward(self, inputs):\n","        article_hist, week_hist = inputs[0], inputs[1]\n","        x = self.article_emb(article_hist)\n","        x = F.normalize(x, dim=2)###[256, 16, 512]\n","        \n","        x, indices = x.max(axis=1)##customer_emb[256,512]\n","        \n","        #x = x@F.normalize(self.article_emb.weight)\n","        \n","        ###get logits rather than probability to generate loss function.\n","        \n","        logits = self.hier(x)\n","        \n","        logits = logits[:,:72582]#remove virtual leaves.\n","\n","        \n","#         x = x.clamp(1e-3, 0.999)\n","#         x = -torch.log(1/x - 1)\n","        \n","#         max_week = week_hist.unsqueeze(2).repeat(1, 1, x.shape[-1]).gather(1, indices.unsqueeze(1).repeat(1, week_hist.shape[1], 1))\n","#         max_week = max_week.mean(axis=1).unsqueeze(1)\n","        \n","#         x = torch.cat([x.unsqueeze(1), max_week,\n","#                        self.article_likelihood[None, None, :].repeat(x.shape[0], 1, 1)], axis=1)\n","        \n","#         x = self.top(x).squeeze(1)\n","        #x = self.Softmax(x)\n","        return logits\n","    \n","    \n","model = HMModel((len(le_article.classes_), 512))\n","model = model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:25.796201Z","iopub.status.busy":"2022-08-13T23:32:25.795489Z","iopub.status.idle":"2022-08-13T23:32:25.815487Z","shell.execute_reply":"2022-08-13T23:32:25.814712Z","shell.execute_reply.started":"2022-08-13T23:32:25.796165Z"},"trusted":true},"outputs":[],"source":["import sys\n","\n","def calc_map(topk_preds, target_array, k=12):\n","    metric = []\n","    tp, fp = 0, 0\n","    \n","    for pred in topk_preds:\n","        if target_array[pred]:\n","            tp += 1\n","            metric.append(tp/(tp + fp))\n","        else:\n","            fp += 1\n","            \n","    return np.sum(metric) / min(k, target_array.sum())\n","\n","def read_data(data):\n","    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n","\n","\n","def validate(model, val_loader, k=12):\n","    model.eval()\n","    \n","    tbar = tqdm(val_loader, file=sys.stdout)\n","    \n","    maps = []\n","    \n","    with torch.no_grad():\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            logits = model(inputs)\n","\n","            _, indices = torch.topk(logits, k, dim=1)\n","\n","            indices = indices.detach().cpu().numpy()\n","            target = target.detach().cpu().numpy()\n","            \n","            for i in range(indices.shape[0]):\n","                maps.append(calc_map(indices[i], target[i]))\n","        \n","    \n","    return np.mean(maps)\n","\n","SEQ_LEN = 16\n","\n","BS = 256\n","NW = 8\n","\n","val_dataset = HMDataset(val_df, SEQ_LEN)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=NW,\n","                          pin_memory=False, drop_last=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Train and validate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:36.809592Z","iopub.status.busy":"2022-08-13T23:32:36.809121Z","iopub.status.idle":"2022-08-13T23:32:36.84048Z","shell.execute_reply":"2022-08-13T23:32:36.839807Z","shell.execute_reply.started":"2022-08-13T23:32:36.809556Z"},"trusted":true},"outputs":[],"source":["def dice_loss(y_pred, y_true):\n","    y_pred = y_pred.sigmoid()\n","    intersect = (y_true*y_pred).sum(axis=1)\n","    \n","    return 1 - (intersect/(intersect + y_true.sum(axis=1) + y_pred.sum(axis=1))).mean()\n","\n","\n","def train(model, train_loader, val_loader, epochs):\n","    np.random.seed(SEED)\n","    \n","    optimizer = get_optimizer(model)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    criterion = torch.nn.functional.cross_entropy\n","    \n","    for e in range(epochs):\n","        model.train()\n","        tbar = tqdm(train_loader, file=sys.stdout)\n","        \n","        lr = adjust_lr(optimizer, e)\n","        \n","        loss_list = []\n","\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            optimizer.zero_grad()\n","            \n","            with torch.cuda.amp.autocast():\n","                logits = model(inputs)\n","                \n","                loss = criterion(logits, target.long())\n","            #loss.backward()\n","            scaler.scale(loss).backward()\n","            #optimizer.step()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            \n","            loss_list.append(loss.detach().cpu().item())\n","            \n","            avg_loss = np.round(100*np.mean(loss_list), 4)\n","\n","            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n","            \n","#         val_map = validate(model, val_loader)\n","\n","#         log_text = f\"Epoch {e+1}\\nTrain Loss: {avg_loss}\\nValidation MAP: {val_map}\\n\"\n","            \n","#         print(log_text)\n","        \n","        #logfile = open(f\"models/{MODEL_NAME}_{SEED}.txt\", 'a')\n","        #logfile.write(log_text)\n","        #logfile.close()\n","    return model\n","\n","\n","MODEL_NAME = \"exp001\"\n","SEED = 0\n","\n","train_dataset = HMDataset(train_df, SEQ_LEN)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n","                          pin_memory=False, drop_last=True)\n","\n","model = train(model, train_loader, val_loader, epochs=10)"]},{"cell_type":"markdown","metadata":{},"source":["### Finetune with more recent data for submission (include validation set)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = HMDataset(train_df[train_df[\"week\"] < 4].append(val_df), SEQ_LEN)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n","                          pin_memory=False, drop_last=True)\n","\n","model = train(model, train_loader, val_loader, epochs=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:45.080067Z","iopub.status.busy":"2022-08-13T23:32:45.079468Z","iopub.status.idle":"2022-08-13T23:32:49.993336Z","shell.execute_reply":"2022-08-13T23:32:49.992564Z","shell.execute_reply.started":"2022-08-13T23:32:45.080029Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv').drop(\"prediction\", axis=1)\n","print(test_df.shape)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:32:54.048633Z","iopub.status.busy":"2022-08-13T23:32:54.047829Z","iopub.status.idle":"2022-08-13T23:33:00.584837Z","shell.execute_reply":"2022-08-13T23:33:00.584118Z","shell.execute_reply.started":"2022-08-13T23:32:54.048581Z"},"trusted":true},"outputs":[],"source":["def create_test_dataset(test_df):\n","    week = -1\n","    test_df[\"week\"] = week\n","    \n","    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n","    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n","    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n","    \n","    \n","    return test_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n","\n","test_df = create_test_dataset(test_df)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-18T13:19:46.236179Z","iopub.status.busy":"2022-03-18T13:19:46.235925Z","iopub.status.idle":"2022-03-18T13:19:46.313921Z","shell.execute_reply":"2022-03-18T13:19:46.313072Z","shell.execute_reply.started":"2022-03-18T13:19:46.236144Z"},"trusted":true},"outputs":[],"source":["test_df[\"article_id\"].isnull().mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-13T23:33:09.285599Z","iopub.status.busy":"2022-08-13T23:33:09.284893Z","iopub.status.idle":"2022-08-13T23:33:30.579046Z","shell.execute_reply":"2022-08-13T23:33:30.576211Z","shell.execute_reply.started":"2022-08-13T23:33:09.28556Z"},"trusted":true},"outputs":[],"source":["test_ds = HMDataset(test_df, SEQ_LEN, is_test=True)\n","test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n","                          pin_memory=False, drop_last=False)\n","\n","\n","def inference(model, loader, k=12):\n","    model.eval()\n","    \n","    tbar = tqdm(loader, file=sys.stdout)\n","    \n","    preds = []\n","    \n","    with torch.no_grad():\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            logits = model(inputs)\n","\n","            _, indices = torch.topk(logits, k, dim=1)\n","\n","            indices = indices.detach().cpu().numpy()\n","            target = target.detach().cpu().numpy()\n","\n","            for i in range(indices.shape[0]):\n","                preds.append(\" \".join(list(le_article.inverse_transform(indices[i]))))\n","        \n","    \n","    return preds\n","\n","\n","test_df[\"prediction\"] = inference(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:20:11.209147Z","iopub.status.idle":"2022-03-18T13:20:11.209811Z","shell.execute_reply":"2022-03-18T13:20:11.209598Z","shell.execute_reply.started":"2022-03-18T13:20:11.209573Z"},"trusted":true},"outputs":[],"source":["test_df.to_csv(\"submission.csv\", index=False, columns=[\"customer_id\", \"prediction\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
