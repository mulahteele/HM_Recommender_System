{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-08-22T19:32:57.681071Z","iopub.status.busy":"2022-08-22T19:32:57.680604Z","iopub.status.idle":"2022-08-22T19:33:41.951493Z","shell.execute_reply":"2022-08-22T19:33:41.950728Z","shell.execute_reply.started":"2022-08-22T19:32:57.681034Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","\n","df = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\", dtype={\"article_id\": str})\n","print(df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:33:41.953059Z","iopub.status.busy":"2022-08-22T19:33:41.952797Z","iopub.status.idle":"2022-08-22T19:33:47.04656Z","shell.execute_reply":"2022-08-22T19:33:47.045807Z","shell.execute_reply.started":"2022-08-22T19:33:41.953024Z"},"trusted":true},"outputs":[],"source":["df[\"t_dat\"] = pd.to_datetime(df[\"t_dat\"])\n","df[\"t_dat\"].max()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:33:47.048003Z","iopub.status.busy":"2022-08-22T19:33:47.047733Z","iopub.status.idle":"2022-08-22T19:33:51.842364Z","shell.execute_reply":"2022-08-22T19:33:51.841668Z","shell.execute_reply.started":"2022-08-22T19:33:47.047967Z"},"trusted":true},"outputs":[],"source":["active_articles = df.groupby(\"article_id\")[\"t_dat\"].max().reset_index()\n","active_articles = active_articles[active_articles[\"t_dat\"] >= \"2019-09-01\"].reset_index()\n","active_articles.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:33:51.845132Z","iopub.status.busy":"2022-08-22T19:33:51.843587Z","iopub.status.idle":"2022-08-22T19:33:59.56848Z","shell.execute_reply":"2022-08-22T19:33:59.567745Z","shell.execute_reply.started":"2022-08-22T19:33:51.845099Z"},"trusted":true},"outputs":[],"source":["df = df[df[\"article_id\"].isin(active_articles[\"article_id\"])].reset_index(drop=True)\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:33:59.571045Z","iopub.status.busy":"2022-08-22T19:33:59.569674Z","iopub.status.idle":"2022-08-22T19:34:01.018483Z","shell.execute_reply":"2022-08-22T19:34:01.017749Z","shell.execute_reply.started":"2022-08-22T19:33:59.571004Z"},"trusted":true},"outputs":[],"source":["df[\"week\"] = (df[\"t_dat\"].max() - df[\"t_dat\"]).dt.days // 7\n","df[\"week\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:34:01.019981Z","iopub.status.busy":"2022-08-22T19:34:01.019696Z","iopub.status.idle":"2022-08-22T19:34:48.502358Z","shell.execute_reply":"2022-08-22T19:34:48.501462Z","shell.execute_reply.started":"2022-08-22T19:34:01.019946Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","\n","article_ids = np.concatenate([[\"placeholder\"], np.unique(df[\"article_id\"].values)])\n","\n","le_article = LabelEncoder()\n","le_article.fit(article_ids)\n","df[\"article_id\"] = le_article.transform(df[\"article_id\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:34:48.504058Z","iopub.status.busy":"2022-08-22T19:34:48.5037Z","iopub.status.idle":"2022-08-22T19:35:21.298378Z","shell.execute_reply":"2022-08-22T19:35:21.297672Z","shell.execute_reply.started":"2022-08-22T19:34:48.504018Z"},"trusted":true},"outputs":[],"source":["WEEK_HIST_MAX = 5\n","\n","def create_dataset(df, week):\n","    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n","    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n","    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n","    \n","    target_df = df[df[\"week\"] == week]\n","    target_df = target_df.groupby(\"customer_id\").agg({\"article_id\": list}).reset_index()\n","    target_df.rename(columns={\"article_id\": \"target\"}, inplace=True)\n","    target_df[\"week\"] = week\n","    \n","    return target_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n","\n","val_weeks = [0]\n","train_weeks = [1, 2, 3, 4]\n","\n","\n","val_df = pd.concat([create_dataset(df, w) for w in val_weeks]).reset_index(drop=True)\n","train_df = pd.concat([create_dataset(df, w) for w in train_weeks]).reset_index(drop=True)\n","train_df.shape, val_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:21.300077Z","iopub.status.busy":"2022-08-22T19:35:21.299781Z","iopub.status.idle":"2022-08-22T19:35:21.306576Z","shell.execute_reply":"2022-08-22T19:35:21.305686Z","shell.execute_reply.started":"2022-08-22T19:35:21.300038Z"},"trusted":true},"outputs":[],"source":["def adjust_lr(optimizer, epoch):\n","    if epoch < 1:\n","        lr = 5e-5\n","    elif epoch < 6:\n","        lr = 1e-3\n","    elif epoch < 9:\n","        lr = 1e-4\n","    else:\n","        lr = 1e-5\n","\n","    for p in optimizer.param_groups:\n","        p['lr'] = lr\n","    return lr\n","    \n","def get_optimizer(net):\n","    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n","                                 eps=1e-08)\n","    return optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:21.308309Z","iopub.status.busy":"2022-08-22T19:35:21.308042Z","iopub.status.idle":"2022-08-22T19:35:21.316506Z","shell.execute_reply":"2022-08-22T19:35:21.31581Z","shell.execute_reply.started":"2022-08-22T19:35:21.308275Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:21.319599Z","iopub.status.busy":"2022-08-22T19:35:21.319307Z","iopub.status.idle":"2022-08-22T19:35:21.332544Z","shell.execute_reply":"2022-08-22T19:35:21.33146Z","shell.execute_reply.started":"2022-08-22T19:35:21.319573Z"},"trusted":true},"outputs":[],"source":["class TreeStructure(nn.Module):\n","    def __init__(self, middle_index, item_index,layer_top_emb,layer_bottom_emb,first_train):\n","        super(TreeStructure, self).__init__()\n","\n","        # Parameters\n","        self.first_train = first_train\n","        self.ntokens = 72582#the number of ouput.(72582)\n","        self.nhid = 512#dimension: the same length of customer dimension.(512)\n","\n","        self.ntokens_per_class = 20#how many children one intermidiate node.(20)\n","\n","        self.nclasses = int(np.ceil(self.ntokens * 1. / self.ntokens_per_class))#intermidiate nodes.(3630)\n","        self.ntokens_actual = self.nclasses * self.ntokens_per_class#72600\n","        if self.first_train:\n","            self.layer_top_emb = nn.Parameter(torch.FloatTensor(self.nclasses,self.nhid), requires_grad=True)\n","            self.layer_bottom_emb = nn.Parameter(torch.FloatTensor(self.ntokens_actual, self.nhid), requires_grad=True)\n","            self.init_weights()\n","            #for K-means to cluster the embedding.(Initialization)\n","            self.middle_index = np.arange(self.nclasses).tolist()\n","            self.item_index = np.arange(self.ntokens_actual).tolist()\n","        else:\n","            #(Inherit from the previous K-means clustering)\n","            self.middle_index = middle_index.tolist()\n","            self.item_index = item_index.tolist()\n","            self.layer_top_emb = nn.Parameter(layer_top_emb, requires_grad=True)\n","            self.layer_bottom_emb = nn.Parameter(layer_bottom_emb, requires_grad=True)\n","            \n","\n","    def init_weights(self):\n","\n","        initrange = 0.1\n","        self.layer_top_emb.data.uniform_(-initrange, initrange)\n","        self.layer_bottom_emb.data.uniform_(-initrange, initrange)\n","\n","\n","    def forward(self, purchase_hist_npos):\n","        #leaf index \n","        hist = purchase_hist_npos\n","        \n","        #nonleaf index\n","        parent_index = (hist/ self.ntokens_per_class).long()#the position after clustering \n","\n","        #leaf embedding\n","        positive_leaf_emb = self.layer_bottom_emb[hist]#positive 1###[256, 512]\n","        negative_leaf_sample = torch.LongTensor(np.random.choice(72600, positive_leaf_emb.shape[0]))###[256] \n","        negative_leaf_emb = self.layer_bottom_emb[negative_leaf_sample]#negative 1###[256, 512]\n","        #nonleaf embedding\n","        positive_nonleaf_emb = self.layer_top_emb[parent_index]#positive 2###[256, 512]\n","        negative_nonleaf_sample = torch.LongTensor(np.random.choice(3630, positive_leaf_emb.shape[0]))\n","        negative_nonleaf_emb = self.layer_top_emb[negative_nonleaf_sample]#negative 2\n","        \n","        \n","        return [positive_leaf_emb,negative_leaf_emb,positive_nonleaf_emb,negative_nonleaf_emb]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:21.334616Z","iopub.status.busy":"2022-08-22T19:35:21.334133Z","iopub.status.idle":"2022-08-22T19:35:22.132646Z","shell.execute_reply":"2022-08-22T19:35:22.131905Z","shell.execute_reply.started":"2022-08-22T19:35:21.334581Z"},"trusted":true},"outputs":[],"source":["class HMModel(nn.Module):\n","    def __init__(self, article_shape,first_train,middle_index, item_index,layer_top_emb,layer_bottom_emb,pre_emb):\n","        super(HMModel, self).__init__()\n","        \n","        self.first_train = first_train\n","        if self.first_train:\n","            self.article_emb = torch.nn.Embedding(article_shape[0], embedding_dim=article_shape[1])\n","            middle_index = torch.ones(1)\n","            item_index = torch.ones(1)\n","            layer_top_emb = torch.ones(1)\n","            layer_bottom_emb = torch.ones(1)\n","        else:\n","            self.article_emb = torch.nn.Embedding.from_pretrained(torch.from_numpy(pre_emb).float())\n","            self.middle_index = middle_index\n","            self.item_index = item_index\n","            self.layer_top_emb = layer_top_emb\n","            self.layer_bottom_emb = layer_bottom_emb\n","            \n","        self.Tree = TreeStructure(middle_index, item_index,layer_top_emb,layer_bottom_emb,first_train=self.first_train)\n","    def forward(self, inputs):\n","        article_hist, week_hist, purchase_hist_npos = inputs[0], inputs[1], inputs[2]\n","        x = self.article_emb(article_hist)\n","        x = F.normalize(x, dim=2)###[256, 16, 512]\n","        \n","        x, indices = x.max(axis=1)##customer_emb[256,512]\n","        \n","        customer_emb = x\n","        \n","        global is_test\n","        \n","        if is_test:\n","            \n","            return customer_emb\n","\n","        #print('0',purchase_hist_item,purchase_hist_item.shape)\n","        \n","        [p1,n1,p2,n2] = self.Tree(purchase_hist_npos)#get four logits for 2 positive and 2 negative samples\n","        \n","        p1_dot = torch.mul(x,p1).sum(dim=1).unsqueeze(0)\n","        n1_dot = torch.mul(x,n1).sum(dim=1).unsqueeze(0)\n","        p2_dot = torch.mul(x,p2).sum(dim=1).unsqueeze(0)\n","        n2_dot = torch.mul(x,n2).sum(dim=1).unsqueeze(0)\n","        \n","        \n","        logits = torch.cat((p1_dot,n1_dot,p2_dot,n2_dot),0).T\n","        \n","        return logits\n","\n","#Train the model at the first time.\n","middle_index = torch.ones(1)\n","item_index = torch.ones(1)\n","layer_top_emb = torch.ones(1)\n","layer_bottom_emb = torch.ones(1)\n","first_train = True\n","global first\n","global is_test\n","is_test = False\n","first = True\n","article_emb = torch.ones(1)\n","\n","model = HMModel((len(le_article.classes_), 512),first_train,middle_index, item_index,layer_top_emb,layer_bottom_emb,article_emb)\n","model = model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:22.134222Z","iopub.status.busy":"2022-08-22T19:35:22.133952Z","iopub.status.idle":"2022-08-22T19:35:22.139358Z","shell.execute_reply":"2022-08-22T19:35:22.138619Z","shell.execute_reply.started":"2022-08-22T19:35:22.134176Z"},"trusted":true},"outputs":[],"source":["global find_index\n","global item_index\n","global first_time\n","first_time = True\n","find_index = torch.ones(1)\n","item_index = torch.ones(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:22.141162Z","iopub.status.busy":"2022-08-22T19:35:22.140481Z","iopub.status.idle":"2022-08-22T19:35:22.152618Z","shell.execute_reply":"2022-08-22T19:35:22.151942Z","shell.execute_reply.started":"2022-08-22T19:35:22.141124Z"},"trusted":true},"outputs":[],"source":["from sklearn.cluster import KMeans\n","def k_means(model):\n","    #Find the current embedding of the tree.\n","    cur_intermidiate_emb = model.Tree.layer_top_emb\n","    cur_bottom_emb = model.Tree.layer_bottom_emb\n","    article_emb = model.article_emb.weight.detach().cpu().numpy()\n","    \n","    #Find the current index of items in the tree.\n","    middle_index = np.array(model.Tree.middle_index)\n","    global item_index\n","    item_index = np.array(model.Tree.item_index)\n","    \n","    #Use embedding to cluster(Get the index after K-means)\n","    kmeans1 = KMeans(n_clusters=50, random_state=0).fit(cur_intermidiate_emb.cpu().detach().numpy())\n","    global find_index\n","    find_index = np.argsort(kmeans1.labels_)\n","    middle_cluster = middle_index[find_index]\n","    print('middle nodes clustering by K-means finished.')\n","\n","    kmeans2 = KMeans(n_clusters=50, random_state=0).fit(cur_bottom_emb.cpu().detach().numpy())\n","    item_cluster = item_index[np.argsort(kmeans2.labels_)]\n","    print('leaf nodes clustering by K-means finished.')\n","    \n","    #Reconstruct embedding matrix using above index(reconstruct tree)\n","    suc_intermidiate_emb = torch.from_numpy(cur_intermidiate_emb.cpu().detach().numpy()[middle_cluster])\n","    suc_bottom_emb = torch.from_numpy(cur_bottom_emb.cpu().detach().numpy()[item_cluster])\n","          \n","           ###3630          ###72600      ###[3630, 512]       ###[72600, 512]\n","    return middle_cluster, item_cluster, suc_intermidiate_emb, suc_bottom_emb, article_emb\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:22.154374Z","iopub.status.busy":"2022-08-22T19:35:22.154109Z","iopub.status.idle":"2022-08-22T19:35:22.186227Z","shell.execute_reply":"2022-08-22T19:35:22.185557Z","shell.execute_reply.started":"2022-08-22T19:35:22.15434Z"},"trusted":true},"outputs":[],"source":["class HMDataset(Dataset):\n","    def __init__(self, df, seq_len, model,is_test=False):\n","        self.df = df.reset_index(drop=True)\n","        self.seq_len = seq_len\n","        self.is_test = is_test\n","        self.model = model\n","    \n","    def __len__(self):\n","        return self.df.shape[0]\n","    \n","    def __getitem__(self, index):\n","        row = self.df.iloc[index]\n","        \n","        if self.is_test:\n","            target = torch.zeros(2).float()\n","        else:\n","            if not row.target:\n","                target = torch.tensor([0]).int()\n","            else:\n","                rand_target = np.random.choice(row.target,1)\n","                target = torch.tensor(rand_target).squeeze().int()\n","#             for t in row.target:\n","#                 target[t] = 1.0\n","#                 break\n","            \n","        article_hist = torch.zeros(self.seq_len).long()\n","        week_hist = torch.ones(self.seq_len).float()\n","        \n","        \n","        if isinstance(row.article_id, list):\n","            if len(row.article_id) >= self.seq_len:\n","                article_hist = torch.LongTensor(row.article_id[-self.seq_len:])\n","                week_hist = (torch.LongTensor(row.week_history[-self.seq_len:]) - row.week)/WEEK_HIST_MAX/2\n","            else:\n","                article_hist[-len(row.article_id):] = torch.LongTensor(row.article_id)\n","                week_hist[-len(row.article_id):] = (torch.LongTensor(row.week_history) - row.week)/WEEK_HIST_MAX/2\n","        target = torch.tensor([1,0,1,0]).float()\n","        \n","        purchase_hist_item = article_hist[-1].numpy()\n","    \n","        tree_item_index = self.model.Tree.item_index\n","        global first_time\n","        global find_index\n","        global item_index\n","        if first_time:\n","            purchase_hist_npos = torch.tensor(purchase_hist_item)\n","        else:\n","            purchase_hist_npos = torch.tensor(find_index[item_index.index(purchase_hist_item)])\n","        \n","\n","        return article_hist, week_hist, purchase_hist_npos, target\n","    \n","HMDataset(val_df, 64,model)[100]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:22.187822Z","iopub.status.busy":"2022-08-22T19:35:22.187585Z","iopub.status.idle":"2022-08-22T19:35:22.222758Z","shell.execute_reply":"2022-08-22T19:35:22.221982Z","shell.execute_reply.started":"2022-08-22T19:35:22.187789Z"},"trusted":true},"outputs":[],"source":["import sys\n","\n","def calc_map(topk_preds, target_array, k=12):\n","    metric = []\n","    tp, fp = 0, 0\n","    \n","    for pred in topk_preds:\n","        if target_array[pred]:\n","            tp += 1\n","            metric.append(tp/(tp + fp))\n","        else:\n","            fp += 1\n","            \n","    return np.sum(metric) / min(k, target_array.sum())\n","\n","def read_data(data):\n","    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n","    #return tuple(d for d in data[:-1]), data[-1]\n","\n","\n","def validate(model, val_loader, k=12):\n","    model.eval()\n","    \n","    tbar = tqdm(val_loader, file=sys.stdout)\n","    \n","    maps = []\n","    \n","    with torch.no_grad():\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            logits = model(inputs)\n","\n","            _, indices = torch.topk(logits, k, dim=1)\n","\n","            indices = indices.detach().cpu().numpy()\n","            target = target.detach().cpu().numpy()\n","            \n","            for i in range(indices.shape[0]):\n","                maps.append(calc_map(indices[i], target[i]))\n","        \n","    \n","    return np.mean(maps)\n","\n","SEQ_LEN = 16\n","\n","BS = 256\n","NW = 8\n","\n","val_dataset = HMDataset(val_df, SEQ_LEN,model)\n","val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=NW,\n","                          pin_memory=False, drop_last=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Train and validate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-22T19:35:48.067231Z","iopub.status.busy":"2022-08-22T19:35:48.066915Z","iopub.status.idle":"2022-08-22T19:39:03.44727Z","shell.execute_reply":"2022-08-22T19:39:03.444411Z","shell.execute_reply.started":"2022-08-22T19:35:48.067199Z"},"trusted":true},"outputs":[],"source":["def dice_loss(y_pred, y_true):\n","    y_pred = y_pred.sigmoid()\n","    intersect = (y_true*y_pred).sum(axis=1)\n","    \n","    return 1 - (intersect/(intersect + y_true.sum(axis=1) + y_pred.sum(axis=1))).mean()\n","\n","\n","def train(model, train_loader, val_loader, epochs):\n","    np.random.seed(SEED)\n","    \n","    optimizer = get_optimizer(model)\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    criterion = nn.BCEWithLogitsLoss()\n","    \n","    for e in range(epochs):\n","        model.train()\n","        tbar = tqdm(train_loader, file=sys.stdout)\n","        \n","        lr = adjust_lr(optimizer, e)\n","        \n","        loss_list = []\n","\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            optimizer.zero_grad()\n","            \n","            with torch.cuda.amp.autocast():\n","                logits = model(inputs)\n","                \n","#                 print('test1',logits,logits.shape)\n","#                 print('test2',target,target.shape)\n","                \n","                loss = criterion(logits, target.float())\n","            #loss.backward()\n","            scaler.scale(loss).backward()\n","            #optimizer.step()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            \n","            loss_list.append(loss.detach().cpu().item())\n","            \n","            avg_loss = np.round(100*np.mean(loss_list), 4)\n","\n","            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n","            \n","#         val_map = validate(model, val_loader)\n","\n","#         log_text = f\"Epoch {e+1}\\nTrain Loss: {avg_loss}\\nValidation MAP: {val_map}\\n\"\n","            \n","#         print(log_text)\n","        \n","        #logfile = open(f\"models/{MODEL_NAME}_{SEED}.txt\", 'a')\n","        #logfile.write(log_text)\n","        #logfile.close()\n","    return model\n","\n","\n","MODEL_NAME = \"exp001\"\n","SEED = 0\n","\n","train_dataset = HMDataset(train_df, SEQ_LEN,model)\n","train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n","                          pin_memory=False, drop_last=True)\n","\n","#first training(Initializing)\n","model = train(model, train_loader, val_loader, epochs=5) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T02:10:27.292136Z","iopub.status.busy":"2022-08-21T02:10:27.291842Z","iopub.status.idle":"2022-08-21T02:21:05.195037Z","shell.execute_reply":"2022-08-21T02:21:05.194173Z","shell.execute_reply.started":"2022-08-21T02:10:27.292104Z"},"trusted":true},"outputs":[],"source":["#Train to reconstruct the interest tree many times after first training.\n","global first\n","first = False\n","def train_tree(model,train_loader,val_loader,epochs):\n","    cluster = k_means(model)\n","    first_train = False\n","    middle_index = cluster[0]\n","    item_index = cluster[1]\n","    layer_top_emb = cluster[2]\n","    layer_bottom_emb = cluster[3]\n","    article_emb = cluster[4]\n","    model = HMModel((len(le_article.classes_), 512),first_train,middle_index, item_index,layer_top_emb,layer_bottom_emb,article_emb)\n","    model = model.cuda()\n","    return train(model, train_loader, val_loader, epochs)\n","\n","epochs = 5\n","train_tree_epochs = 1\n","for _ in range(train_tree_epochs):\n","    train_dataset = HMDataset(train_df, SEQ_LEN,model)\n","    train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=NW,\n","                          pin_memory=False, drop_last=True)\n","    model = train_tree(model,train_loader,val_loader,epochs)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T02:21:15.351264Z","iopub.status.busy":"2022-08-21T02:21:15.350618Z","iopub.status.idle":"2022-08-21T02:21:17.743337Z","shell.execute_reply":"2022-08-21T02:21:17.742546Z","shell.execute_reply.started":"2022-08-21T02:21:15.351227Z"},"trusted":true},"outputs":[],"source":["test_df = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv').drop(\"prediction\", axis=1)\n","print(test_df.shape)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T02:21:19.997873Z","iopub.status.busy":"2022-08-21T02:21:19.997241Z","iopub.status.idle":"2022-08-21T02:21:26.328909Z","shell.execute_reply":"2022-08-21T02:21:26.328183Z","shell.execute_reply.started":"2022-08-21T02:21:19.997822Z"},"trusted":true},"outputs":[],"source":["def create_test_dataset(test_df):\n","    week = -1\n","    test_df[\"week\"] = week\n","    \n","    hist_df = df[(df[\"week\"] > week) & (df[\"week\"] <= week + WEEK_HIST_MAX)]\n","    hist_df = hist_df.groupby(\"customer_id\").agg({\"article_id\": list, \"week\": list}).reset_index()\n","    hist_df.rename(columns={\"week\": 'week_history'}, inplace=True)\n","    \n","    \n","    return test_df.merge(hist_df, on=\"customer_id\", how=\"left\")\n","\n","test_df = create_test_dataset(test_df)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T01:45:34.601479Z","iopub.status.busy":"2022-08-21T01:45:34.600884Z","iopub.status.idle":"2022-08-21T01:45:34.663856Z","shell.execute_reply":"2022-08-21T01:45:34.662927Z","shell.execute_reply.started":"2022-08-21T01:45:34.601433Z"},"trusted":true},"outputs":[],"source":["test_df[\"article_id\"].isnull().mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T02:21:55.447171Z","iopub.status.busy":"2022-08-21T02:21:55.446716Z","iopub.status.idle":"2022-08-21T02:21:55.450877Z","shell.execute_reply":"2022-08-21T02:21:55.450011Z","shell.execute_reply.started":"2022-08-21T02:21:55.447135Z"},"trusted":true},"outputs":[],"source":["global is_test\n","is_test = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-21T02:23:09.808396Z","iopub.status.busy":"2022-08-21T02:23:09.807927Z","iopub.status.idle":"2022-08-21T02:23:12.887363Z","shell.execute_reply":"2022-08-21T02:23:12.886325Z","shell.execute_reply.started":"2022-08-21T02:23:09.808359Z"},"trusted":true},"outputs":[],"source":["test_ds = HMDataset(test_df, SEQ_LEN, model,is_test=True)\n","test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False, num_workers=NW,\n","                          pin_memory=False, drop_last=False)\n","\n","\n","def inference(model, loader, k=12):\n","    model.eval()\n","    \n","    tbar = tqdm(loader, file=sys.stdout)\n","    \n","    preds = []\n","    \n","    with torch.no_grad():\n","        for idx, data in enumerate(tbar):\n","            inputs, target = read_data(data)\n","\n","            customer_emb = model(inputs)\n","                \n","            dot_top_layer = torch.matmul(customer_emb,model.Tree.layer_top_emb.T)\n","            _ , indices = torch.topk(dot_top_layer, 12, dim=1)\n","            indices = indices.detach().cpu().numpy()\n","\n","            search_item = np.array(model.Tree.item_index)\n","            search_item = np.where(search_item >= 72582, 0, search_item)\n","            bottom_layer = model.Tree.layer_bottom_emb ##[0*indice,0*indice+20]\n","            \n","            for i in range(len(indices)):\n","                for j in range(12):\n","                    dot = torch.matmul(customer_emb[i],bottom_layer[indices[i][j]*20:indices[i][j]*20+20].T)\n","                    _ , item_pos = torch.topk(dot, 1, dim=0)\n","                    item_pos = indices[i][j]*20 + item_pos\n","                    indices[i][j] = search_item[item_pos]\n","   \n","            for i in range(len(indices)):\n","                preds.append(\" \".join(list(le_article.inverse_transform(indices[i]))))\n","                \n","    return preds\n","\n","\n","test_df[\"prediction\"] = inference(model, test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-03-18T13:20:11.209147Z","iopub.status.idle":"2022-03-18T13:20:11.209811Z","shell.execute_reply":"2022-03-18T13:20:11.209598Z","shell.execute_reply.started":"2022-03-18T13:20:11.209573Z"},"trusted":true},"outputs":[],"source":["test_df.to_csv(\"submission.csv\", index=False, columns=[\"customer_id\", \"prediction\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
