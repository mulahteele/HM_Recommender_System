{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports and prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:00:41.926997Z","iopub.status.busy":"2022-06-10T18:00:41.926Z","iopub.status.idle":"2022-06-10T18:00:41.964615Z","shell.execute_reply":"2022-06-10T18:00:41.963604Z","shell.execute_reply.started":"2022-06-10T18:00:41.92684Z"},"trusted":true},"outputs":[],"source":["import time\n","import numpy as np\n","import pandas as pd\n","\n","import multiprocessing as mp\n","from multiprocessing import Pool\n","from functools import partial"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-10T18:00:48.004508Z","iopub.status.busy":"2022-06-10T18:00:48.004041Z","iopub.status.idle":"2022-06-10T18:02:19.772Z","shell.execute_reply":"2022-06-10T18:02:19.770998Z","shell.execute_reply.started":"2022-06-10T18:00:48.004471Z"},"trusted":true},"outputs":[],"source":["base_path = '../input/h-and-m-personalized-fashion-recommendations/'\n","csv_train = f'{base_path}transactions_train.csv'\n","csv_sub = f'{base_path}sample_submission.csv'\n","csv_users = f'{base_path}customers.csv'\n","csv_items = f'{base_path}articles.csv'\n","\n","df = pd.read_csv(csv_train, dtype={'article_id': str}, parse_dates=['t_dat'])\n","df_sub = pd.read_csv(csv_sub)"]},{"cell_type":"markdown","metadata":{},"source":["# Create mapping from ids to incremental integers and viceversa\n","\n","* We will reserve the term `user_id` as a integer from 0 and `customer_id` for the original id.\n","* The same goes with `item_id` and `article_id`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:02:33.858322Z","iopub.status.busy":"2022-06-10T18:02:33.857475Z","iopub.status.idle":"2022-06-10T18:02:42.521832Z","shell.execute_reply":"2022-06-10T18:02:42.520735Z","shell.execute_reply.started":"2022-06-10T18:02:33.858274Z"},"trusted":true},"outputs":[],"source":["dfu = pd.read_csv(csv_users)\n","dfi = pd.read_csv(csv_items, dtype={'article_id': str})\n","\n","ALL_USERS = dfu['customer_id'].unique().tolist()\n","ALL_ITEMS = dfi['article_id'].unique().tolist()\n","\n","user_to_customer_map = {user_id: customer_id for user_id, customer_id in enumerate(ALL_USERS)}\n","customer_to_user_map = {customer_id: user_id for user_id, customer_id in enumerate(ALL_USERS)}\n","\n","item_to_article_map = {item_id: article_id for item_id, article_id in enumerate(ALL_ITEMS)}\n","article_to_item_map = {article_id: item_id for item_id, article_id in enumerate(ALL_ITEMS)}\n","\n","del dfu, dfi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:02:47.271583Z","iopub.status.busy":"2022-06-10T18:02:47.271255Z","iopub.status.idle":"2022-06-10T18:03:05.712291Z","shell.execute_reply":"2022-06-10T18:03:05.711092Z","shell.execute_reply.started":"2022-06-10T18:02:47.27155Z"},"trusted":true},"outputs":[],"source":["df['user_id'] = df['customer_id'].map(customer_to_user_map)\n","df['item_id'] = df['article_id'].map(article_to_item_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:03:17.179691Z","iopub.status.busy":"2022-06-10T18:03:17.179396Z","iopub.status.idle":"2022-06-10T18:03:17.193466Z","shell.execute_reply":"2022-06-10T18:03:17.192667Z","shell.execute_reply.started":"2022-06-10T18:03:17.179662Z"},"trusted":true},"outputs":[],"source":["print(df.head())"]},{"cell_type":"markdown","metadata":{},"source":["# Build model"]},{"cell_type":"markdown","metadata":{},"source":["# Configuration parameters"]},{"cell_type":"markdown","metadata":{},"source":["Since UUCF is very computationally expensive, we will apply it only to a small subset of users. The hope is that, for those users, the recommendation are better than the other models.\n","\n","We will reduce the data from 2 fronts:\n","* Keep only the most recent history. That is `START_DATE`.\n","* Keep only users with at least `MINIMUM_PURCHASES`"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T21:09:04.36672Z","iopub.status.busy":"2022-06-10T21:09:04.366416Z","iopub.status.idle":"2022-06-10T21:09:04.371231Z","shell.execute_reply":"2022-06-10T21:09:04.370565Z","shell.execute_reply.started":"2022-06-10T21:09:04.366672Z"},"trusted":true},"outputs":[],"source":["N_SIMILAR_USERS = 30\n","\n","MINIMUM_PURCHASES = 2\n","\n","START_DATE = '2020-07-20'\n","\n","DROP_PURCHASED_ITEMS = False\n","\n","DROP_USER_FROM_HIS_NEIGHBORHOOD = False\n","\n","TEST_RUN = False\n","\n","TEST_SIZE = 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T19:31:48.206924Z","iopub.status.busy":"2022-06-10T19:31:48.206608Z","iopub.status.idle":"2022-06-10T19:31:48.2366Z","shell.execute_reply":"2022-06-10T19:31:48.23587Z","shell.execute_reply.started":"2022-06-10T19:31:48.20689Z"},"trusted":true},"outputs":[],"source":["def flatten(l):\n","    \"\"\" Flatten a list of lists\"\"\"\n","    return [item for sublist in l for item in sublist]\n","\n","def compare_vectors(v1, v2):\n","    \"\"\"Compare lists of purchased product for two given users\n","    v1 stands for the \"vector representation for user 1\", which is a list of the purchases of u1\n","    \n","    Returns:\n","        A value between 0 and 1 (similarity)\n","    \"\"\"\n","    intersection = len(set(v1) & set(v2))\n","    denominator = np.sqrt(len(v1) * len(v2))\n","    return intersection / denominator\n","\n","def get_similar_users(u, v, dfh):\n","    \"\"\"\n","    Get the N_SIMILAR_USERS most similar users to the given one with their similarity score\n","    Arguments:\n","        u: the user_id, \n","        v:  the \"vector\" representation of the user (list of item_id)\n","        dfh : the \"history of transaccions\" dataframe\n","        \n","    Returns:\n","        tuple of lists ([similar user_id], [similarity scores])\n","    \"\"\"\n","    similar_users = dfh.sample(n=1000).apply(lambda v_other: compare_vectors(v, v_other)).sort_values(ascending=False).head(N_SIMILAR_USERS + 1)\n","    \n","    if DROP_USER_FROM_HIS_NEIGHBORHOOD:\n","        similar_users = similar_users[similar_users.index != u]\n","        \n","    return similar_users.index.tolist(), similar_users.tolist()\n","\n","def get_items(u, v, dfh):\n","    \"\"\" Get the recommend items for a given users\n","    \n","    It will:\n","        1) Get similar users for the given user\n","        2) Obtain all the items those users purchased\n","        3) Rank them using the similarity scores of the user that purchased them\n","        4) Return the 12 best ranked\n","    \n","    Arguments:\n","        u: the user_id, \n","        v:  the \"vector\" representation of the user (list of item_id)\n","        dfh : the \"history of transaccions\" dataframe\n","        \n","    Returns:\n","        list of item_id of lenght at most 12\n","    \"\"\"\n","    global i, n\n","    \n","    users, scores = get_similar_users(u, v, dfh)\n","    df_nn = pd.DataFrame({'user': users, 'score': scores})\n","    df_nn['items'] = df_nn.apply(lambda row: dfh.loc[row.user], axis=1)\n","    df_nn['weighted_items'] = df_nn.apply(lambda row: [(item, row.score) for item in row['items']], axis=1)\n","\n","    recs = pd.DataFrame(flatten(df_nn['weighted_items'].tolist()), columns=['item', 'score']).groupby('item')['score'].sum().sort_values(ascending=False)\n","    if DROP_PURCHASED_ITEMS:\n","        recs = recs[~recs.index.isin(v)]\n","    # Keep the first 12 and get the item_ids\n","    i +=1\n","    if i % 200 == 0:\n","        pid = mp.current_process().pid\n","        print(f\"[PID {pid:>2d}] Finished {i:3d} / {n:5d} - {i/n*100:3.0f}%\")\n","    return recs.head(12).index.tolist()\n","\n","def get_items_chunk(user_ids: np.array, dfh: pd.DataFrame):\n","    \"\"\" Call get_item for a list of user_ids\n","    \n","    Arguments:\n","        user_ids: list of user_id, \n","        dfh: the \"history of transaccions\" dataframe\n","        \n","    Returns:\n","        pd.Series with index user_id and list of item_id (recommendations) as value\n","    \"\"\"\n","    global i, n\n","    i = 0\n","    \n","    n = len(user_ids)\n","    pid = mp.current_process().pid\n","    print(f\"[PID {pid:>2d}] Started working with {n:5d} users\")\n","    \n","    df_user_vectors = pd.DataFrame(dfh.loc[user_ids]).reset_index()\n","    df_user_vectors['recs'] = df_user_vectors.apply(lambda row: get_items(row.user_id, row.item_id, dfh), axis=1)\n","    return df_user_vectors.set_index('user_id')['recs']\n","\n","def get_recommendations(users: list, dfh: pd.DataFrame):\n","    \"\"\"\n","    Obtained recommendation for the users using transaccion dfh in a parallelized manner\n","    \n","    Call get_items_chunk in a \"smart\" multiprocessing fashion\n","    \n","    Arguments:\n","        users: list of user_id\n","        dfh: the \"history of transaccions\" dataframe\n","    \n","    Returns:\n","        pd.DataFrame with index user_id and list of item_id (recommendations) as value\n","    \n","    \"\"\"\n","    time_start = time.time()\n","    \n","    # Split into approximately evenly sized chunks\n","    # We will send just one batch to each CPU \n","    user_chunks = np.array_split(users, mp.cpu_count())\n","    \n","    f = partial(get_items_chunk, dfh=dfh)\n","    with Pool(mp.cpu_count()) as p:\n","        res = p.map(f, user_chunks)\n","    \n","    df_rec = pd.DataFrame(pd.concat(res))\n","\n","    elapsed = (time.time() - time_start) / 60\n","    print(f\"Finished get_recommendations({len(users)}). It took {elapsed:5.2f} mins\")\n","    return df_rec\n","\n","\n","def uucf(df, start_date=START_DATE):\n","    \"\"\" Entry point for the UUCF model. \n","    \n","    Receive the original transactions_train.csv and a start_date and gets UUCF recommendations\n","    \n","    The model will not cover the full list of users, but just a subset of them.\n","    \n","    It will provide recommendations for users with at least MINIMUM_PURCHASES after start_date.\n","    It might return less than 12 recs per user.\n","    \n","    An ad-hoc function for filling these gaps should be used downstream.\n","    (See fill functionality right below)\n","    \n","    \n","    Arguments:\n","        df: The raw dataframe from transactions_train.csv\n","        start_date: a date\n","        \n","    Returns:\n","        a submission-like pd.DataFrame with columns [customer_id, prediction]\n","        'prediction' is a list and not a string though\n","    \n","    \"\"\"\n","    df_small = df[df[\"t_dat\"] >= START_DATE]\n","    print(f\"Kept data from {start_date} on. Total rows: {len(df_small)}\")\n","    \n","    # H stands for \"Transaction history\"\n","    # dfh is a series of user_id => list of item_id (the list of purchases in order)\n","    dfh = df_small.groupby(\"user_id\")['item_id'].apply(lambda items: list(set(items)))\n","    dfh = dfh[dfh.str.len() >= MINIMUM_PURCHASES]\n","    if TEST_RUN:\n","        print(\"WARNING: TEST_RUN is True. It will be a toy execution.\")\n","        dfh = dfh.head(TEST_SIZE)\n","    \n","    users = dfh.index.tolist()\n","    n_users = len(users)\n","    print(f\"Total users in the time frame with at least {MINIMUM_PURCHASES}: {n_users}\")\n","    df_rec = get_recommendations(users, dfh)\n","    df_rec['customer_id'] = df_rec.index.map(user_to_customer_map)\n","    df_rec['prediction'] = df_rec['recs'].map(lambda l: [item_to_article_map[i] for i in l])\n","    \n","    # Submission ready dataframe\n","    df_rec.reset_index(drop=True)[['customer_id', 'prediction']]\n","    return df_rec "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T19:31:53.03302Z","iopub.status.busy":"2022-06-10T19:31:53.032555Z","iopub.status.idle":"2022-06-10T20:51:02.161143Z","shell.execute_reply":"2022-06-10T20:51:02.16002Z","shell.execute_reply.started":"2022-06-10T19:31:53.032987Z"},"trusted":true},"outputs":[],"source":["df_recs = uucf(df)"]},{"cell_type":"markdown","metadata":{},"source":["# Fill the remainder with another model\n","We will use [Heng Zheng](https://www.kaggle.com/hengzheng)'s [time is our best friend v2](https://www.kaggle.com/hengzheng/time-is-our-best-friend-v2/) which is simple and the best performing public model as of today.\n","\n","I have created a dataset with the submission file from that notebook [here](https://www.kaggle.com/julian3833/heng-zhengs-time-is-our-best-friend-v2-submission)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:19:07.493636Z","iopub.status.busy":"2022-06-10T18:19:07.493195Z","iopub.status.idle":"2022-06-10T18:19:12.730094Z","shell.execute_reply":"2022-06-10T18:19:12.728609Z","shell.execute_reply.started":"2022-06-10T18:19:07.493597Z"},"trusted":true},"outputs":[],"source":["csv_fill = '../input/h-m-content-based-12-most-popular-items-0-007/submission.csv'\n","df_fill = pd.read_csv(csv_fill)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:26:33.992126Z","iopub.status.busy":"2022-06-10T18:26:33.991848Z","iopub.status.idle":"2022-06-10T18:26:34.003144Z","shell.execute_reply":"2022-06-10T18:26:34.001956Z","shell.execute_reply.started":"2022-06-10T18:26:33.992095Z"},"trusted":true},"outputs":[],"source":["len(df_recs['prediction'].tolist()[99933])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T18:19:15.779502Z","iopub.status.busy":"2022-06-10T18:19:15.778698Z","iopub.status.idle":"2022-06-10T18:19:15.793634Z","shell.execute_reply":"2022-06-10T18:19:15.792646Z","shell.execute_reply.started":"2022-06-10T18:19:15.779414Z"},"trusted":true},"outputs":[],"source":["def drop_duplicates(seq):\n","    \"\"\" Remove duplicates of a given sequence keeping order\"\"\"\n","    seen = set()\n","    seen_add = seen.add\n","    return [x for x in seq if not (x in seen or seen_add(x))]\n","\n","def fill_row(row):\n","    uucf = row['prediction_uucf']\n","    fill = row['prediction_fill'].split()\n","    new_list = drop_duplicates(uucf + fill)[:12]\n","    return ' '.join(new_list)\n","\n","\n","def fill(df_recs, df_fill):\n","    df_recs['len'] = df_recs['prediction'].str.len()\n","    df_recs = pd.merge(df_fill, df_recs, how='left', on='customer_id', suffixes=('_fill', '_uucf'))\n","# No recs from UUCF at all: use the fallback model \n","    df_recs.loc[df_recs['prediction_uucf'].isnull(), 'prediction'] = df_recs['prediction_fill']\n","\n","\n","    # Full UUCF recommendation\n","    mask = df_recs['prediction_uucf'].notnull() & (df_recs['len'] == 12)\n","    df_recs.loc[mask, 'prediction'] = df_recs['prediction_uucf']\n","\n","\n","    # Fill with another model. Not enough recs from UUCF\n","    fill_mask = df_recs['prediction_uucf'].notnull() & (df_recs['len'] < 12)\n","    df_recs.loc[fill_mask, 'prediction'] = df_recs[fill_mask].apply(fill_row, axis=1)\n","    return df_recs.drop(['prediction_uucf', 'prediction_fill', 'len', 'recs'], axis=1)\n","    \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fill with another model\n","df_sub = fill(df_recs, df_fill)\n","df_sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-15T20:04:46.254431Z","iopub.status.busy":"2022-02-15T20:04:46.253639Z","iopub.status.idle":"2022-02-15T20:04:46.26274Z","shell.execute_reply":"2022-02-15T20:04:46.261979Z","shell.execute_reply.started":"2022-02-15T20:04:46.25439Z"},"trusted":true},"outputs":[],"source":["df_sub.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-10T21:08:11.021694Z","iopub.status.busy":"2022-06-10T21:08:11.021335Z","iopub.status.idle":"2022-06-10T21:08:11.111949Z","shell.execute_reply":"2022-06-10T21:08:11.110776Z","shell.execute_reply.started":"2022-06-10T21:08:11.021599Z"},"trusted":true},"outputs":[],"source":["# Submit\n","df_sub.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Please, _DO_ upvote if you find this kernel useful or interesting!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
